{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://machinelearningmastery.com/super-learner-ensemble-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a super learner for regression using the mlens library\n",
    "from math import sqrt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from mlens.ensemble import SuperLearner\n",
    "\n",
    "# create a list of base-models\n",
    "def get_models():\n",
    "\tmodels = list()\n",
    "\tmodels.append(LinearRegression())\n",
    "\tmodels.append(ElasticNet())\n",
    "\tmodels.append(SVR(gamma='scale'))\n",
    "\tmodels.append(DecisionTreeRegressor())\n",
    "\tmodels.append(KNeighborsRegressor())\n",
    "\tmodels.append(AdaBoostRegressor())\n",
    "\tmodels.append(BaggingRegressor(n_estimators=10))\n",
    "\tmodels.append(RandomForestRegressor(n_estimators=10))\n",
    "\tmodels.append(ExtraTreesRegressor(n_estimators=10))\n",
    "\treturn models\n",
    "\n",
    "# cost function for base models\n",
    "def rmse(yreal, yhat):\n",
    "\treturn sqrt(mean_squared_error(yreal, yhat))\n",
    "\n",
    "# create the super learner\n",
    "def get_super_learner(X):\n",
    "\tensemble = SuperLearner(scorer=rmse, folds=10, shuffle=True, sample_size=len(X))\n",
    "\t# add base models\n",
    "\tmodels = get_models()\n",
    "\tensemble.add(models)\n",
    "\t# add the meta model\n",
    "\tensemble.add_meta(LinearRegression())\n",
    "\treturn ensemble\n",
    "\n",
    "# create the inputs and outputs\n",
    "X, y = make_regression(n_samples=1000, n_features=100, noise=0.5)\n",
    "# split\n",
    "X, X_val, y, y_val = train_test_split(X, y, test_size=0.50)\n",
    "print('Train', X.shape, y.shape, 'Test', X_val.shape, y_val.shape)\n",
    "# create the super learner\n",
    "ensemble = get_super_learner(X)\n",
    "# fit the super learner\n",
    "ensemble.fit(X, y)\n",
    "# summarize base learners\n",
    "print(ensemble.data)\n",
    "# evaluate meta model\n",
    "yhat = ensemble.predict(X_val)\n",
    "print('Super Learner: RMSE %.3f' % (rmse(y_val, yhat)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
